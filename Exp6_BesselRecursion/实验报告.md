# 实验六：球贝塞尔函数的递推关系与数值稳定性实验报告

## 1. 实验目的
1. 实现并比较球贝塞尔函数的向上和向下递推计算方法
2. 理解并掌握向下递推结果的归一化方法
3. 通过实验观察和分析不同递推方法的数值稳定性
4. 深入理解数值计算中的误差放大和抑制机制

## 2. 实验原理
### 2.1 球贝塞尔函数
球贝塞尔函数 $j_l(x)$ 满足二阶线性常微分方程：
$$ x^2 f''(x) + 2xf'(x) + [x^2 - l(l+1)]f(x) = 0 $$

最低阶的两个函数解析形式：
$$ j_0(x) = \frac{\sin x}{x} $$
$$ j_1(x) = \frac{\sin x}{x^2} - \frac{\cos x}{x} $$

### 2.2 递推关系
1. 向上递推：
   $$ j_{l+1}(x) = \frac{2l+1}{x} j_l(x) - j_{l-1}(x) $$

2. 向下递推：
   $$ j_{l-1}(x) = \frac{2l+1}{x} j_l(x) - j_{l+1}(x) $$

### 2.3 归一化方法
向下递推结果的归一化：
$$ j_l^\mathrm{normalized}(x) = j_l^\mathrm{compute}(x) \times \frac{j_0^\mathrm{analytic}(x)}{j_0^\mathrm{compute}(x)} $$

## 3. 实验方法
### 3.1 代码实现
1. `bessel_up(x, lmax)` 函数实现：
   - （描述实现方法）
   - （初始值选取）
     # 初始化结果数组
    j = np.zeros(lmax + 1)

    # 计算初始值
    j[0] = np.sin(x) / x if x != 0 else 1.0  # j_0(x)
    if lmax > 0:
        j[1] = np.sin(x) / x ** 2 - np.cos(x) / x  # j_1(x)
   
   - （递推过程）
   # 向上递推
    for l in range(1, lmax):
        j[l + 1] = (2 * l + 1) / x * j[l] - j[l - 1]

    return j

3. `bessel_down(x, lmax, m_start)` 函数实现：
   - （描述实现方法）
   - （初始值选取）
       if m_start is None:
        m_start = lmax + 15

    # 初始化临时数组，用于向下递推
    j_temp = np.zeros(m_start + 2)

    # 设置初始值
    j_temp[m_start + 1] = 0.0
    j_temp[m_start] = 1.0
   - （递推过程）
       # 向下递推
    for l in range(m_start, 0, -1):
        j_temp[l - 1] = (2 * l + 1) / x * j_temp[l] - j_temp[l + 1]

   - （归一化方法）
    # 计算解析的j_0(x)用于归一化
    j0_analytic = np.sin(x) / x if x != 0 else 1.0

    # 归一化
    scale = j0_analytic / j_temp[0]
    j = j_temp[:lmax + 1] * scale
   
### 3.2 数据收集与处理
1. 测试点选取：x = 0.1, 1.0, 10.0
2. 计算范围：l = 0 到 25
3. 与scipy.special.spherical_jn比较
4. 误差计算方法

## 4. 实验结果
### 4.1 数值结果
| x | l | $j_l^\mathrm{up}(x)$ | $j_l^\mathrm{down}(x)$ | $j_l^\mathrm{scipy}(x)$ |
|---|---|----------------------|------------------------|-------------------------|
| 0.1 | 3 |     9.518517e-06   |      9.518520e-06     |     9.518520e-06     |
| 0.1 | 5 |    -1.445698e-08      |     9.616310e-10     |    9.616310e-10      |
| 0.1 | 8 |    -3.306558e-02     |   2.901200e-16    |     2.901200e-16        |
| 1.0 | 3 |    9.006581e-03    |     9.006581e-03        |   9.006581e-03        |
| ... | ... |                    |                        |                         |

### 4.2 误差分析图
（在此插入三个x值对应的半对数图）
![capture_20250416224512360](https://github.com/user-attachments/assets/6d50374b-c286-4e14-bfa0-351139efd39b)
![capture_20250416224259099](https://github.com/user-attachments/assets/80dc9c95-6492-449f-925c-b29225ed8f11)
![capture_20250416224315858](https://github.com/user-attachments/assets/e96ab56b-9676-445f-831e-1449a0f7fcfa)

## 5. 分析与讨论
### 5.1 数值稳定性分析
1. 向上递推的不稳定性：
   - 失效区域分析（l > x时的表现）   当 x 较小时，球贝塞尔函数值随阶数 n 增加而急剧减小（如 j_n(x) ~ x^n）。向上递推时，初始误差会被逐级放大，导致高阶函数值完全失真。
   - 误差放大机制分析   递推公式 j_{n+1}(x) = (2n+1)/x * j_n(x) - j_{n-1}(x) 中，系数 (2n+1)/x 在 x < 1 时远大于1，导致前一步误差被指数级放大。
   - 与球诺伊曼函数的关系   向上递推对球诺伊曼函数 y_n(x) 同样不稳定，但其绝对值随 n 增大而增长，可能掩盖部分误差

2. 向下递推的稳定性：
   - 误差抑制机制   向下递推时，误差以 O(x/n) 的比例衰减。高阶项的初始误差在传递到低阶时被自然抑制。
   - 归一化的作用   通过从高阶（如 n=m_start）开始，假设 j_{m_start}(x)≈0 并归一化到已知的 j_0(x) 或 j_1(x)，可避免绝对误差累积。  
   - 计算精度分析   在双精度浮点下，向下递推的相对误差通常保持在 1e-15 以下，但需合理选择 m_start

### 5.2 计算效率比较
1. 两种方法的计算时间对比   向上递推：时间复杂度 O(n)，但仅适用于低阶或 x ≫ n 的稳定区域。向下递推：需额外计算高阶初始值，时间复杂度 O(m_start)，但通用性更强
2. 影响计算效率的因素分析   x 的大小：x 越小，向下递推所需的 m_start 越高，耗时增加。阶数范围：计算 n=0~100 时，若 x=100，向上递推可能更快；若 x=0.1，向下递推是唯一选择。

## 6. 结论
1. 两种递推方法的适用条件   向上递推：仅适用于 x ≫ n 的场景（如 x > 2n）。向下递推：通用性强，尤其适合 x < n 或高精度需求。
2. 数值稳定性的重要性   向上递推在 x < 1 时完全失效，而向下递推能保证全参数范围内的可靠性。
3. 归一化在提高计算精度中的作用   通过从高阶向下归一化到已知低阶值，可显著减少累积误差，提升精度。

## 7. 思考题
1. 为什么向上递推在l > x时会变得不稳定？
核心原因是递推系数 (2n+1)/x 放大误差，而 j_n(x) 的真实值随 n 增加快速衰减，导致相对误差爆炸。
2. 向下递推为什么能够有效抑制误差？
误差传递系数为 O(x/n)，当 n 从高阶向低阶递减时，误差逐步衰减。数学上，向下递推对应一个收缩映射。
3. 如何选择合适的m_start值以保证计算精度？
经验公式：m_start ≈ max(n_{\text{max}}, 1.5x + 30)，其中 n_{\text{max}} 为目标最高阶数。
动态调整：可基于 j_{m_start}(x) 的绝对值是否小于机器精度（如 1e-20）来判断是否足够大。
## 附录：关键代码
```python
# 在此粘贴关键代码实现
```

def bessel_up(x, lmax):
    j[0] = np.sin(x) / x if x != 0 else 1.0  # j_0(x)
    if lmax > 0:
        j[1] = np.sin(x) / x ** 2 - np.cos(x) / x  # j_1(x)

    # 向上递推
    for l in range(1, lmax):
        j[l + 1] = (2 * l + 1) / x * j[l] - j[l - 1]

    return j
def bessel_down(x, lmax, m_start=None):
    if m_start is None:
        m_start = lmax + 15

    # 初始化临时数组，用于向下递推
    j_temp = np.zeros(m_start + 2)

    # 设置初始值
    j_temp[m_start + 1] = 0.0
    j_temp[m_start] = 1.0

    # 向下递推
    for l in range(m_start, 0, -1):
        j_temp[l - 1] = (2 * l + 1) / x * j_temp[l] - j_temp[l + 1]

    # 计算解析的j_0(x)用于归一化
    j0_analytic = np.sin(x) / x if x != 0 else 1.0

    # 归一化
    scale = j0_analytic / j_temp[0]
    j = j_temp[:lmax + 1] * scale

    return j
    
