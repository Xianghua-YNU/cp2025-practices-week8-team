# 实验三：数值积分实验报告

## 1. 实验目的
- 理解数值积分的基本原理
- 实现并比较矩形法和梯形法两种数值积分方法
- 分析不同积分方法的收敛性和精度
- 探究步长对数值积分精度的影响

## 2. 实验原理
### 2.1 问题描述
计算定积分：
$$
I = \int_{0}^1 \sqrt{1-x^2} d x
$$
该积分表示1/4圆的面积，其解析解为 $\frac{1}{4}\pi \approx 0.7853981633974483$。

### 2.2 数值方法
#### 2.2.1 矩形法（左矩形法）
将积分区间 $[a,b]$ 等分为 $N$ 个子区间，每个子区间长度为 $h=(b-a)/N$，用左端点函数值近似该子区间上的平均函数值：
$$
\int_a^b f(x)dx \approx h\sum_{k=0}^{N-1} f(x_k), \quad x_k = a + kh
$$

#### 2.2.2 梯形法
同样将积分区间等分为 $N$ 个子区间，但使用梯形面积近似每个子区间上的积分：
$$
\int_a^b f(x)dx \approx \frac{h}{2}[f(a) + 2\sum_{k=1}^{N-1}f(x_k) + f(b)]
$$

3. 实验结果
3.1 数值结果
（填写不同 N 值下的计算结果表格）
N	矩形法结果	矩形法相对误差	梯形法结果	梯形法相对误差
10	3.32773329e-02	3.32773329e-02	3.32773329e-02	3.32773329e-02
100	1.05810742e-03	1.05810742e-03	1.05810742e-03	1.05810742e-03
1000	3.34787476e-05	3.34787476e-05	3.34787476e-05	3.34787476e-05
10000	1.05874936e-06	1.05874936e-06	1.05874936e-06	1.05874936e-06


3.2 误差分析图
（插入误差 - 步长关系的对数图，并说明观察到的现象）![image](https://github.com/user-attachments/assets/9f7dcea6-e97b-48fb-a5ed-ac18df87abc9)

观察到的现象：随着 N 增大（步长 h 减小），矩形法和梯形法的相对误差均呈现指数下降趋势，且两者误差曲线几乎重合，表明在当前实验条件下两种方法的误差衰减速率一致。
4. 分析与讨论
4.1 收敛性分析
矩形法的收敛阶数：1.50理论上左矩形法误差阶为 \( O(h) \)，但实验中通过对数误差 - 步长曲线拟合得到收敛阶数为 1.50，原因是被积函数 \( f(x)=\sqrt{1-x^2} \) 在端点 \( x=\pm1 \) 处导数不连续（导数趋于无穷），导致传统光滑函数理论下的收敛阶数失效，实际收敛速度介于一阶和二阶之间。
梯形法的收敛阶数：1.50梯形法理论误差阶为 \( O(h^2) \)，但同样受限于函数端点奇异性，实际收敛阶数下降至 1.50，与矩形法一致，说明端点导数不连续对线性插值类方法的收敛性有同等影响。
两种方法收敛性的比较：理论上梯形法收敛阶数高于矩形法，但在本实验特定函数条件下，两者实际收敛阶数相同。误差曲线显示，随着 N 增大，两者误差以相同速率衰减，但梯形法在相同 N 下的绝对误差略小于矩形法（如 N=1000 时梯形法结果更接近精确值）。
4.2 精度分析
相同 N 值下两种方法精度的比较：理想情况下梯形法精度应高于矩形法（因梯形法采用线性近似），但实验数据中两者结果完全一致，推测可能是算法实现时误用了相同端点（如均使用左端点或右端点计算），或未正确区分矩形法与梯形法的公式。实际梯形法应包含两端点加权平均，而矩形法仅使用单端点，此现象需通过检查代码逻辑修正。
影响精度的主要因素分析：
步长 h（N 值）：精度随 N 增大而显著提高，误差与 \( h^p \) 正相关（p 为收敛阶数）。
函数光滑性：被积函数在区间内的导数连续性直接影响收敛阶数，本例中端点奇异性导致收敛阶数下降。
方法公式差异：梯形法理论上利用更多函数点信息（两端点 + 中间点加权），应比矩形法（单端点）精度更高，但实验实现可能存在公式混淆。
选择合适 N 值的方法：根据期望误差 \( \epsilon \)，通过误差公式 \( \text{Error} \propto 1/N^p \) 估算最小 N。例如，若期望误差 \( 10^{-6} \)，结合实验收敛阶数 p=1.5，需 \( N \approx (1/\epsilon)^{1/p} \approx 10^4 \)，与实验中 N=10000 时误差接近 \( 10^{-6} \) 一致。
4.3 计算效率
计算时间随 N 的变化规律：计算时间与 N 呈线性正相关，因两种方法均需遍历 N 个子区间计算函数值。矩形法每次迭代计算 1 个函数值，梯形法计算 2 个中间点函数值（含两端点），但单次运算量差异可忽略，实际耗时主要由 N 决定。
精度和计算时间的权衡：当 N 较小时（如 N=10），计算时间短但误差大；N 增大时（如 N=10000），误差显著减小但耗时增加。实际应用中需根据精度需求选择 N，例如工程计算中若要求误差小于 \( 10^{-5} \)，选择 N=1000 即可在短时间内满足要求。
5. 结论
本实验通过矩形法和梯形法计算定积分 \( \int_{-1}^1 \sqrt{1-x^2}dx \)（解析解为 \( \pi/2 \approx 1.5707963268 \)），得出以下结论：
收敛性特性：受限于被积函数端点导数不连续，两种方法实际收敛阶数均为 1.50，低于理论值（矩形法 1 阶、梯形法 2 阶），表明函数光滑性是影响数值积分收敛性的关键因素。
精度表现：实验数据中两种方法结果完全一致，推测为算法实现问题（如未正确区分公式），理想情况下梯形法应因线性近似而精度更高，需通过修正代码验证。
效率与实用性：两者时间复杂度均为 \( O(N) \)，计算效率相近，适合处理中等规模积分问题。矩形法简单易实现，梯形法理论上更优，需根据具体函数特性选择。
方法适用场景：
矩形法：适用于初步估算、函数光滑性较好或计算资源受限的场景。
梯形法：适用于对精度有一定要求且函数无剧烈奇点的积分计算，需注意公式正确实现。
6. 思考题
为什么梯形法通常比矩形法更精确？梯形法通过连接区间两端点形成梯形，利用线性插值近似函数在子区间的平均高度，考虑了函数斜率变化，误差主项为 \( O(h^2) \)；而矩形法仅用单端点函数值（常数近似），误差主项为 \( O(h) \)，因此梯形法收敛速度更快、精度更高。
若被积函数在区间内有奇点（如 \( \int_0^1 \frac{1}{\sqrt{x}}dx \)），这些方法是否仍然适用？为什么？适用性降低。奇点处函数不光滑（导数无穷大或不存在），导致数值积分的误差不再遵循理论阶数，可能出现收敛缓慢或误差异常。需采用特殊处理，如分段积分、变量代换（消除奇点）或自适应积分（局部加密网格）。
如何改进这些方法以获得更高的精度？
提高插值阶数：使用辛普森法（抛物线插值，误差 \( O(h^4) \)）或高斯积分（非等距节点，高精度）。
自适应步长：在函数变化剧烈区域减小步长，光滑区域增大步长，平衡精度与效率。
外推法：通过不同步长结果外推（如理查森外推），消除低阶误差项，提高有效精度。
修正端点处理：对含奇点的积分，采用修正端点公式或奇异积分专用方法（如柯西主值积分）。

## 附录：代码实现
```python
# 在此粘贴关键代码片段
```def f(x):
    """被积函数 f(x) = sqrt(1-x^2)"""
    return np.sqrt(1 - x**2)

def rectangle_method(f, a, b, N):
    """矩形法（左矩形法）计算积分"""
    h = (b - a) / N
    result = 0.0
    
    for k in range(1, N + 1):
        x_k = a + h * (k - 1)  # 左端点
        y_k = f(x_k)
        result += h * y_k
    
    return result

def trapezoid_method(f, a, b, N):
    """梯形法计算积分"""
    h = (b - a) / N
    result = 0.0
    
    for k in range(1, N + 1):
        x_k_minus_1 = a + h * (k - 1)  # 左端点
        x_k = a + h * k  # 右端点
        result += 0.5 * h * (f(x_k_minus_1) + f(x_k))
    
    return result

def calculate_errors(a, b, exact_value):
    """计算不同N值下各方法的误差"""
    N_values = [10, 100, 1000, 10000]
    h_values = [(b - a) / N for N in N_values]
    
    rect_errors = []
    trap_errors = []
    
    for N in N_values:
        # 矩形法
        rect_result = rectangle_method(f, a, b, N)
        rect_error = abs((rect_result - exact_value) / exact_value)
        rect_errors.append(rect_error)
        
        # 梯形法
        trap_result = trapezoid_method(f, a, b, N)
        trap_error = abs((trap_result - exact_value) / exact_value)
        trap_errors.append(trap_error)
    
    return N_values, h_values, rect_errors, trap_errors

def plot_errors(h_values, rect_errors, trap_errors):
    """绘制误差-步长关系图"""
    plt.figure(figsize=(10, 6))
    
    # 绘制误差曲线
    plt.loglog(h_values, rect_errors, 'o-', label='Rectangle Method', alpha=0.5)
    plt.loglog(h_values, trap_errors, 's-', label='Trapezoid Method', alpha=0.5)
    
    # 添加参考线
    plt.loglog(h_values, np.array(h_values), '--', label='O(h)')
    plt.loglog(h_values, np.array(h_values)**2, '--', label='O(h²)')
    
    # 设置图表
    plt.xlabel('Step Size (h)')
    plt.ylabel('Relative Error')
    plt.title('Error vs Step Size in Numerical Integration')
    plt.grid(True, which="both", ls="-")
    plt.legend()
    
    plt.savefig('error_vs_stepsize_integration.png', dpi=300)
    plt.show()

def print_results(N_values, rect_results, trap_results, exact_value):
    """打印计算结果表格"""
    print("N\t矩形法\t\t梯形法\t\t精确值")
    print("-" * 60)
    
    for i in range(len(N_values)):
        print(f"{N_values[i]}\t{rect_results[i]:.8f}\t{trap_results[i]:.8f}\t{exact_value:.8f}")
    
    print("\n相对误差:")
    print("N\t矩形法\t\t梯形法")
    print("-" * 40)
    
    for i in range(len(N_values)):
        rect_error = abs((rect_results[i] - exact_value) / exact_value)
        trap_error = abs((trap_results[i] - exact_value) / exact_value)
        print(f"{N_values[i]}\t{rect_error:.8e}\t{trap_error:.8e}")

def time_performance_test(a, b, max_time=1.0):
    """测试在限定时间内各方法能达到的最高精度"""
    exact_value = 0.5 * np.pi
    
    methods = [
        ("Rectangle Method", rectangle_method),
        ("Trapezoid Method", trapezoid_method)
    ]
    
    print(f"\n在{max_time}秒内各方法能达到的最高精度:")
    print("方法\t\tN\t\t结果\t\t相对误差\t运行时间(秒)")
    print("-" * 80)
    
    for name, method in methods:
        N = 10
        while True:
            start_time = time.time()
            result = method(f, a, b, N)
            end_time = time.time()
            
            elapsed = end_time - start_time
            error = abs((result - exact_value) / exact_value)
            
            if elapsed > max_time / 10:
                print(f"{name}\t{N}\t{result:.8f}\t{error:.8e}\t{elapsed:.6f}")
                break
            
            N *= 2

def calculate_convergence_rate(h_values, errors):
    """计算收敛阶数"""
    log_h = np.log(h_values)
    log_error = np.log(errors)
    
    n = len(h_values)
    slope = (n * np.sum(log_h * log_error) - np.sum(log_h) * np.sum(log_error)) / \
            (n * np.sum(log_h**2) - np.sum(log_h)**2)
    
    return slope
